{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a script that sets up the QAQC portion of the 2015 WY Roads Update project.  It accomplishes the following:\n",
    "* Randomly selects 5 24k quads for each 100k quad throughout the state.  This represents the areas where QAQC will take place.\n",
    "* Clips the working roads layers to the 24k quads.\n",
    "* Creates point layers that will represent the location along each road where the QAQC assessment will take place.  A point is randomly placed on every road within the selected 24k quads.\n",
    "* The random point layers are exported the their corresponding feature datasets within the working file geodatabase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set workspace, initiate empty list that will house our Feature Classes\n",
    "workspace = <<path to working file geodatabase>>\n",
    "fcs = []\n",
    "\n",
    "#Walk the file geodatabase looking for the 100k quad Feature Classes we are interested in\n",
    "walk = arcpy.da.Walk(workspace, datatype=\"FeatureClass\")\n",
    "\n",
    "for dirpath, dirnames, filenames in walk:\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('QuadBoundaries'):\n",
    "            fcs.append(os.path.join(dirpath, filename))\n",
    "            \n",
    "fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dissolve our Feature Classes so that they consist of just one feature, export to shapefile.  \n",
    "#Add shapefiles to an empty list.\n",
    "diss_shps = []\n",
    "Dissovled_100kQuads = <<path to folder where Dissovled_100kQuads will be written>>\n",
    "\n",
    "for fc in fcs:\n",
    "    out_feature = os.path.join(Dissovled_100kQuads, fc.rsplit('\\\\', 1)[-1] + '.shp')\n",
    "    diss_shps.append(out_feature)\n",
    "    arcpy.Dissolve_management(fc, out_feature)\n",
    "    \n",
    "diss_shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set workspace, overwrite option, and variables.\n",
    "arcpy.env.workspace = <<path to folder where Dissovled_100kQuads are>>\n",
    "arcpy.env.overwriteOutput = True \n",
    "    \n",
    "sel_quads = <<path to where Selected24kQuads.shp is>>\n",
    "Clipped_24kQuads = <<path to where Clipped_24kQuads will be written>>\n",
    "clip_shps = []\n",
    "\n",
    "#Select the randomly selected quads that have their centroid within each of the dissolved shapefiles.  \n",
    "#Export the selection to new shapefiles.\n",
    "for shp in diss_shps:\n",
    "    out_clip = os.path.join(Clipped_24kQuads, shp.rsplit('\\\\', 1)[-1].split('_')[0] + '_24kQuads.shp')\n",
    "    clip_shps.append(out_clip)\n",
    "    \n",
    "    arcpy.MakeFeatureLayer_management(sel_quads, \"sel_quads\")\n",
    "    \n",
    "    selection = arcpy.SelectLayerByLocation_management(\"sel_quads\", \"HAVE_THEIR_CENTER_IN\", shp, \"\", \"NEW_SELECTION\")\n",
    "    \n",
    "    #Ensure the correct amount of features are being selected.\n",
    "    matchcount = int(arcpy.GetCount_management(selection)[0]) \n",
    "    print(matchcount)\n",
    "    \n",
    "    arcpy.CopyFeatures_management(selection, out_clip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Walk the file geodatabase looking for the road Feature Classes we are interested in\n",
    "walk_rd = arcpy.da.Walk(workspace, datatype=\"FeatureClass\")\n",
    "fc_rd = []\n",
    "\n",
    "for dirpath, dirnames, filenames in walk_rd:\n",
    "    for filename in filenames:\n",
    "        if 'Road' in filename:\n",
    "            fc_rd.append(os.path.join(dirpath, filename))\n",
    "            \n",
    "roads = fc_rd[-5:]\n",
    "roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip the roads layers to the randomly selected 24k quads, then create a point shapefile that contains randomly generated\n",
    "#points, one for each road.\n",
    "\n",
    "rnd_pt_list = []\n",
    "Clipped_Roads = << path to where Clipped_Roads will be written>>\n",
    "Random_Points = << path to where Random_Points will be written>>\n",
    "\n",
    "for rd in roads:\n",
    "    out_clip_rd = os.path.join(Clipped_Roads, rd.rsplit('\\\\', 1)[-1].split('_')[0] + '_WYRoads_Clip.shp')\n",
    "    arcpy.Clip_analysis(rd, sel_quads, out_clip_rd)\n",
    "    arcpy.AddField_management(out_clip_rd, \"Random\", \"SHORT\")\n",
    "    arcpy.CalculateField_management(out_clip_rd, \"Random\", \"1\", \"PYTHON_9.3\")\n",
    "    rnd_pts = arcpy.CreateRandomPoints_management(out_path=Random_Points, \n",
    "                                    out_name=(out_clip_rd.rsplit('\\\\', 1)[-1].rsplit('_', 1)[0] + '_RandomPt'),\n",
    "                                    constraining_feature_class=out_clip_rd, constraining_extent=\"0 0 250 250\",\n",
    "                                    number_of_points_or_field=\"Random\", minimum_allowed_distance=\"50 Meters\",\n",
    "                                    create_multipoint_output=\"POINT\", multipoint_size=\"0\")\n",
    "    rnd_pt_list.append(rnd_pts)\n",
    "    \n",
    "    print(out_clip_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Randomly select half of the points to be assessed during QAQC.  This creates a more manageable, but still statistically\n",
    "#significant subset.  Add fields that will be used to track errors and progress.\n",
    "\n",
    "#Code block for input to Calculate Field operation.\n",
    "codeblock = \"\"\"\n",
    "def rand_num():  \n",
    "    import random  \n",
    "    return random.randint(0,1)\"\"\"\n",
    "\n",
    "for pt in rnd_pt_list:\n",
    "    #Add fields\n",
    "    arcpy.AddField_management(pt, \"Random\", \"SHORT\")\n",
    "    arcpy.AddField_management(pt, \"Attr_Err\", \"TEXT\", field_length='1')\n",
    "    arcpy.AddField_management(pt, \"Pos_Err\", \"TEXT\", field_length='1')\n",
    "    arcpy.AddField_management(pt, \"Om_Err\", \"TEXT\", field_length='1')\n",
    "    arcpy.AddField_management(pt, \"Com_Err\", \"TEXT\", field_length='1')\n",
    "    arcpy.AddField_management(pt, \"Assessed\", \"TEXT\", field_length='1')\n",
    "    #Randomly assign 0 or 1 to all values in 'Random' columns.  Only values with '1' will be assessed.\n",
    "    arcpy.CalculateField_management(in_table=pt, field=\"Random\", expression='rand_num()', expression_type=\"PYTHON_9.3\",\n",
    "                                    code_block=codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set workspace, initiate empty list that will house our Feature Datasets\n",
    "workspace = <<path to working file geodatabase>>\n",
    "fdatasets = []\n",
    "\n",
    "\n",
    "walk = arcpy.da.Walk(workspace, datatype=\"FeatureDataset\")\n",
    "for dirpath, dirnames, filenames in walk:\n",
    "    if 'Block' in dirpath:\n",
    "        fdatasets.append(dirpath)\n",
    "        \n",
    "#Sort feature dataset list alphabetically, so the items will correspond correctly to the list of point datasets.\n",
    "sort = sorted(fdatasets)\n",
    "sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a range [0,1,2] to index the lists\n",
    "workRange = range(len(rnd_pt_list))\n",
    "\n",
    "for thisIndex in workRange:\n",
    "    # step through the lists one by one, and create a variable that will become the output name.\n",
    "    shp = rnd_pt_list[thisIndex]\n",
    "    fds = sort[thisIndex]\n",
    "    temp = shp.rsplit('\\\\', 1)[-1].split('.')[0]\n",
    "    # Export random point shapefiles to the corresponding feature datasets within the working file geodatabase.\n",
    "    arcpy.FeatureClassToFeatureClass_conversion(shp, fds, temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
